{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LNSHRIVAS/News-article-classification-using-bayesian-learning/blob/main/Bayesian_Learning_for_Classifying_Internet_News_Text_Articles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "X1YS4rDAGbI5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import shutil\n",
        "import tarfile\n",
        "import shutil\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eou8ibaDK-f",
        "outputId": "83649f49-e7df-41e2-f2b1-e97a194cafc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TIMVSN6pDagh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wXjHvY5cZjOc"
      },
      "outputs": [],
      "source": [
        "data = '/content/drive/MyDrive/Data/20_newsgroups.tar.gz'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RYPiiR4rZL_1"
      },
      "outputs": [],
      "source": [
        "import tarfile\n",
        "with tarfile.open(data, 'r:gz') as tar:\n",
        "    tar.extractall(path='/content/20_newsgroups')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfQEo-XPN-fr",
        "outputId": "4963bcf1-af14-4d2f-ec21-d42580e34a74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of data files: 19997\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "def count_files(directory):\n",
        "    file_count = 0\n",
        "\n",
        "    # Walk through the directory and count the files\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        file_count += len(files)\n",
        "\n",
        "    return file_count\n",
        "\n",
        "extracted_data_path = '/content/drive/MyDrive/Data/20_newsgroups_extracted'\n",
        "\n",
        "total_files = count_files(extracted_data_path)\n",
        "\n",
        "print(f'Total number of data files: {total_files}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "e7kUKJ1gyodN"
      },
      "outputs": [],
      "source": [
        "folder_path = '/content/drive/MyDrive/Data/20_newsgroups_extracted/20_newsgroups'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hw1E0Fz0uOS"
      },
      "outputs": [],
      "source": [
        "news_directory = {}\n",
        "categories = os.listdir(folder_path)\n",
        "\n",
        "for category in categories:\n",
        "    categories_path = os.path.join(folder_path, category)\n",
        "\n",
        "    news_directory[category] = []\n",
        "    for filename in os.listdir(categories_path):\n",
        "        file_path = os.path.join(categories_path, filename)\n",
        "        print(file_path)\n",
        "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "            relavent_text = f.readlines()\n",
        "            p_text = relavent_text[25:]\n",
        "            required_text = ''.join(p_text).strip()\n",
        "            news_directory[category].append(required_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len((news_directory)['alt.atheism']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtNA4nU1MgCC",
        "outputId": "d374803b-79a8-48b8-a725-b9ac0b4c03f4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's say you want to check the first 3 entries for each category\n",
        "for label in list(news_directory.keys())[:3]:  # Adjust the range as needed\n",
        "    print(f\"Category: {label}\")\n",
        "    # Print the first few documents under this category\n",
        "    for i, document in enumerate(news_directory[label][:3]):  # Print first 3 documents\n",
        "        print(f\"Document {i + 1}: {document[:200]}...\")  # Print first 200 characters\n",
        "    print(\"\\n\" + \"-\" * 50 + \"\\n\")  # Separator between categories\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRCibvZSJ2y2",
        "outputId": "55b38bfc-97e8-44a9-e716-e973fee50501"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Category: comp.windows.x\n",
            "Document 1: >>screen/display to another.\n",
            "> \n",
            "> As to how many clients may be display on a server, I believe the limit\n",
            "> would be how much memory is available to your server or allocated by the\n",
            "> server.\n",
            "> \n",
            "\n",
            "This a...\n",
            "Document 2: but It is often better to buy than to redevelop the more complex \n",
            "widgets, especially if you only one customer to distribute to. \n",
            "\n",
            "This is the extent that I know about them except that I got their \n",
            "da...\n",
            "Document 3: \\Bernhard....\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Category: comp.sys.ibm.pc.hardware\n",
            "Document 1: - DOS doesn't monitor IRQ 7; it uses other means to determine when it's\n",
            "   time to send out another byte to the printer.\n",
            "\n",
            " - Most (all?) (hardware) printer adapters have the ability to disable\n",
            "   the ...\n",
            "Document 2: At the moment , I have been using the ESDI drive and recently I bought a IDE drive to use as the 2nd drive . \n",
            "The person in the computer shop told me that it is not possible to run 2 disk controller c...\n",
            "Document 3: I heard that there is a cheap sound board that has SCSI controller built-in?\n",
            "What's quality of this board? How much usually does a SCSI control cost?\n",
            "Is there any ftp sites that has SyQuest driver or ...\n",
            "\n",
            "--------------------------------------------------\n",
            "\n",
            "Category: sci.crypt\n",
            "Document 1: Version: 2.1\n",
            "\n",
            "\n",
            "IDENTITY, PRIVACY, and ANONYMITY on the INTERNET\n",
            "================================================\n",
            "\n",
            "(c) 1993 L. Detweiler.  Not for commercial use except by permission\n",
            "from author, other...\n",
            "Document 2: blocks.  (Anyone know a cheap way of converting every atom in the solar\n",
            "system into a one bit storage device?)\n",
            " \n",
            "   Actually, a keysearch of this kind shouldn't be much worse than the\n",
            "simpler kind in ...\n",
            "Document 3: ...\n",
            "\n",
            "--------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Training_data = {}\n",
        "Testing_data = {}\n",
        "\n",
        "for category in news_directory:\n",
        "  content = news_directory[category]\n",
        "\n",
        "  data_split = int(0.8 * len(content))\n",
        "\n",
        "  Training_data[category] = content[:data_split]\n",
        "  Testing_data[category] = content[data_split:]\n"
      ],
      "metadata": {
        "id": "tXvCdh51XVO1"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(Training_data['alt.atheism']))\n",
        "print(len(Testing_data['alt.atheism']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jp2tYYfYaY_x",
        "outputId": "49300e90-7368-455a-92a3-bb7d6173cd8a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "800\n",
            "200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for category in Training_data:\n",
        "\n",
        "  Training_tokens = []\n",
        "  Testing_tokens = []\n",
        "  for document in Training_data[category]:\n",
        "    filtered_text = document.translate(str.maketrans('', '', string.punctuation))\n",
        "    filtered_text = filtered_text.lower()\n",
        "    tokens = filtered_text.split()\n",
        "    Training_tokens.extend(tokens)\n",
        "\n",
        "  for document in Testing_data[category]:\n",
        "    filtered_text = document.translate(str.maketrans('', '', string.punctuation))\n",
        "    filtered_text = filtered_text.lower()\n",
        "    tokens = filtered_text.split()\n",
        "    Testing_tokens.extend(tokens)"
      ],
      "metadata": {
        "id": "Qc3a0estayhS"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(Training_tokens))\n",
        "print(len(Testing_tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1CkNYVKewKB",
        "outputId": "254e2a5c-019b-44f3-aa96-4fba8ef46328"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "297747\n",
            "89158\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Combined_Training_tokens = []\n",
        "\n",
        "Combined_Training_tokens.extend(Training_tokens)\n",
        "\n",
        "print(len(Combined_Training_tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VL367AVFipmn",
        "outputId": "07a358bf-3e9b-40ff-82e7-bad37a763b16"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "297747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Frequent_word_count = {}\n",
        "\n",
        "for word in Combined_Training_tokens:\n",
        "  Frequent_word_count[word] = Frequent_word_count.get(word, 0) + 1"
      ],
      "metadata": {
        "id": "z-v8aJWpkCGo"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Frequent_word_list = []\n",
        "\n",
        "for word, count in Frequent_word_count.items():\n",
        "    Frequent_word_list.append((word, count))\n",
        "\n",
        "for i in range(len(Frequent_word_list)):\n",
        "    for j in range(i + 1, len(Frequent_word_list)):\n",
        "        if Frequent_word_list[i][1] < Frequent_word_list[j][1]:\n",
        "\n",
        "            Frequent_word_list[i], Frequent_word_list[j] = Frequent_word_list[j], Frequent_word_list[i]"
      ],
      "metadata": {
        "id": "dIBMG4s4kfWB"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Top_200_Most_Frequent_words = Frequent_word_list[:200]"
      ],
      "metadata": {
        "id": "qCE9HNTYl0HN"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Top_200_Most_Frequent_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfkJqAZBmKwV",
        "outputId": "c227f4fa-e140-48be-ace0-798000193462"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('the', 18863), ('of', 9673), ('and', 7726), ('to', 7544), ('in', 6183), ('a', 4886), ('that', 3981), ('i', 3198), ('is', 3132), ('it', 2391), ('you', 2312), ('for', 2225), ('was', 2149), ('not', 2045), ('they', 1995), ('as', 1982), ('on', 1894), ('are', 1865), ('by', 1803), ('were', 1681), ('with', 1560), ('from', 1435), ('this', 1435), ('have', 1420), ('be', 1366), ('we', 1206), ('their', 1179), ('there', 1143), ('he', 1103), ('no', 1034), ('or', 1010), ('but', 1009), ('who', 998), ('all', 997), ('at', 982), ('an', 978), ('people', 939), ('had', 919), ('if', 887), ('what', 866), ('one', 801), ('turkish', 797), ('them', 792), ('my', 772), ('do', 770), ('armenian', 737), ('israel', 732), ('would', 714), ('has', 712), ('when', 684), ('his', 679), ('will', 675), ('its', 664), ('about', 653), ('so', 649), ('which', 640), ('jews', 636), ('said', 629), ('been', 624), ('out', 618), ('armenians', 603), ('me', 585), ('your', 559), ('other', 545), ('some', 526), ('any', 525), ('us', 522), ('only', 505), ('then', 494), ('can', 476), ('our', 455), ('more', 452), ('just', 435), ('like', 434), ('these', 431), ('now', 429), ('jewish', 422), ('into', 415), ('israeli', 415), ('even', 410), ('because', 410), ('turks', 403), ('those', 403), ('also', 402), ('armenia', 402), ('government', 393), ('up', 392), ('know', 392), ('dont', 385), ('such', 378), ('how', 377), ('war', 364), ('did', 363), ('after', 361), ('against', 358), ('turkey', 352), ('than', 349), ('first', 349), ('right', 341), ('arab', 341), ('well', 336), ('many', 333), ('new', 330), ('say', 316), ('could', 316), ('should', 308), ('over', 306), ('see', 303), ('time', 303), ('him', 302), ('years', 300), ('university', 299), ('state', 295), ('history', 288), ('why', 287), ('two', 287), ('her', 283), ('think', 282), ('world', 275), ('greek', 272), ('where', 269), ('way', 267), ('killed', 266), ('most', 265), ('may', 263), ('she', 260), ('being', 259), ('russian', 254), ('rights', 250), ('same', 247), ('genocide', 246), ('am', 245), ('children', 244), ('during', 244), ('arabs', 242), ('might', 239), ('get', 234), ('human', 232), ('work', 230), ('muslim', 229), ('muslims', 229), ('between', 229), ('does', 229), ('soldiers', 227), ('fact', 223), ('go', 222), ('today', 221), ('under', 218), ('here', 218), ('population', 217), ('while', 215), ('never', 213), ('before', 210), ('make', 210), ('peace', 210), ('part', 206), ('political', 204), ('last', 204), ('still', 201), ('too', 197), ('both', 195), ('villages', 193), ('must', 193), ('1', 193), ('since', 191), ('very', 190), ('went', 190), ('through', 188), ('azerbaijan', 188), ('going', 188), ('want', 188), ('ed', 187), ('istanbul', 185), ('back', 183), ('ottoman', 182), ('didnt', 182), ('country', 181), ('off', 180), ('soviet', 179), ('adl', 178), ('land', 178), ('down', 177), ('greece', 177), ('2', 177), ('own', 176), ('left', 173), ('again', 171), ('called', 170), ('take', 170), ('told', 169), ('im', 168), ('came', 166), ('group', 165), ('york', 164), ('come', 164), ('p', 163), ('home', 162), ('three', 162), ('made', 162), ('dead', 161)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Unique_Training_Tokens = set()\n",
        "Unique_Testing_Tokens = set()\n",
        "\n",
        "for document in Training_tokens:\n",
        "  Unique_Training_Tokens.update(document)\n",
        "\n",
        "for document in Testing_tokens:\n",
        "  Unique_Testing_Tokens.update(document)"
      ],
      "metadata": {
        "id": "4aOOiK7Of5vY"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QiCIEngPg9Nh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/kRvxdYTcYLGsa6Hkg4x5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}